### What makes science...science?

First, let's go through a few common ways
people might answer this question.

#### Defining science by process


The process of science is often summarized by
a simple loop:

<ol>
    <li>Identify some property of the world
        around us that seems to be
        universally true.</li>
    <li>Identify the logical consequences of
        that property.</li>
    <li>Test for the logical consequences,
        and keep poking around until you're
        either unable to falsify your theory
        given your operating constraints or
        until you've found some
        inconsistency.</li>
    <li>When an inconsistency is found,
        return to step 1 and identify the
        new universal property.</li>
</ol>
<!--
 -->
<!-- Of course, science often engages in some -->
<!-- seriously meta games. It might be that -->
<!-- instead of observing first some symmetry of -->
<!-- the universe, we instead first observe a -->
<!-- bunch of particles in our collider that -->
<!-- we know mathematically would emerge in the -->
<!-- case when there is some underlying symmetry -->
<!-- (which may actually predict many other -->
<!-- particles that we have not seen before). -->
<!-- This doesn't really follow the 4-step plan I -->
<!-- lay out above (even though it is obviously -->
<!-- an example of extremely good science). -->
<!-- However, it does follow the gestalt of the -->
<!-- above, in that it involves identifying a -->
<!-- specific set  of mathematical (i.e. -->
<!-- axiomatizeable) "assumptions" whose logical -->
<!-- consequences can be directly tested. -->
<!--  -->
#### Defining science as "model-driven"


The cornerstone of the process described
above is what I'd call the "successful,
falsifiable model".

<ul>
    <li>
        By <em>"model"</em>, I mean a
        mathematical description of some
        process that generates observations
        of the world around us. (Where
        mathematical simply means it is
        unambiguous, and has unambiguous
        logical consequences).
    </li>
    <li>
        By <em>"successful"</em>, I mean
        that we can be reasonably confident
        that the model will remain accurate
        upon continued testing.
    </li>
    <li>
        Finally, by <em>"falsifiable"</em>,
        I mean that every "assumption" of
        the model can in principle be tested.
    </li>
</ul>


You might notice in particular that I've
punted hundreds of years of philosophy of
science into the catch-all phrase:
"reasonably confident".  This is not because
I don't understand the complexity involved
in trying to specify exactly what are the
properties that should make one "reasonably
confident" that a model will remain accurate
upon adding further measurements. Rather, it
is exactly because I admit that I personally
believe that "good" science (as currently
practiced) is basically just a huge grab bag
of heuristics for what kinds of models are
useful (e.g.  those that have stood the test
of time and repeated verification, those
that are as simple as possible, those that
rely on the fewest unmeasured parameters,
etc). And while I think these are important
for doing "good" science, in practice, they
are ignored by working scientists as needed
to accomplish their particular goals.



In particular, notice that I don't include
any notion of the "simplicity" of the model
in my definition of science. That is in fact
because I actively do not think that science
is necessarily about the pursuit of the
"simplest possible" model of a system. In
fact, I tend to actually <a
href="#blog.physics-vs-biology">define
physics</a>
as the subset of science whose sole purpose
is to generate the most simple model of a
system possible given existing data.

#### Defining science as leveraging logic to facilitate the search for truth

Science turns out to be a word which is
used to describe quite a diverse range of
activities that are undertaken in the search
of knowledge.
<ul>
    <li>(exploratory experimentation and
        hypothesis development)
        Broadly, searching for underlying
        universal properties of the world
        around us by looking for patterns in
        observations.</li>
    <li>(theoretical development) Developing the logical consequences
        of existing ("known") patterns in
        the world around us.</li>
    <li>(experimental verification and
        falsification) "known" consequences
        of "known" patterns in the world
        around us to look for discrepancies,
        since these will stem (in a real
        model) from incorrect assumptions
        that should be revised.</li>
</ul>
<!--
By "universal properties" above, I don't -->
<!-- necessarily mean "fundamental" or -->
<!-- "simplest", just "reproducible". Even -->
<!-- without a complete understanding of -->
<!-- epigenetics, we were able to map out how -->
<!-- gene expression works for some easy -->
<!-- bacterial genes early on (e.g. the -->
<!-- <i>lac</i> operon). The principle that a -->
<!-- transcription factor needs to be chemically -->
<!-- modified by the environment and bind to the -->
<!-- promoter was not a "universal" or -->
<!-- "fundamental" description of how gene -->
<!-- expression works, but it was the best -->
<!-- description that we had (and agreed with all -->
<!-- data available at the level of -->
<!-- coarse-graining that was required by models -->
<!-- of the time). -->


However, if we simply go around calling
everything that seems to fit in this
extremely broad framework by the name
"science", we will find that it does not
distinguish very well between well-respected
theories and total quack science.

#### Things that aren't science
##### #1: Unverifiable models


Models that can only be distinguished from
other models via predictions that can not be
verified in any way are not scientific.



This most famously includes string theory,
but also encompasses certain types of model
selection that are normally relegated to
Occam's razor as a special case. For
example, when comparing between a model of
gravity and a model where gravity has
identically the same properties but is
generated by an unmeasurable space fairy
that orbits outside the milky way, the
latter can be dismissed out of hand as being
unscientific. If we replace the space fairy
with a massive obelist in low-earth orbit,
now the latter theory is at least scientific
(it is testable) although it is true that
heuristically, it makes sense to dismiss it
out of hand (this is Occam's razor), the
reasons we dismiss it are totally different,
even if they seem similar.

##### #2: statistics


More importantly than what exact choices I
made in my definition of "science" are the
things that I explicitly disinclude from
"science" using my definition above. For
example, most of what the statistics
community would call a "model" (note I'm
explicitly not talking about stochastic
versions of physics models, which are also
often called "statistical") would not be
included.



When is fitting, let's say, a
linear model, considered science? It's
easiest to see by example. When measuring
the velocity of something falling on the
moon, it seems to make scientific sense to
fit this (possibly noisy) data to a linear
model. This is because we have hundreds of
years of data suggesting that an
approximately constant force of gravity will
be the only real contributor to the motion,
and so we expect that if we measured
everything more accurately (decreasing the
noise) that the linear model would continue
to describe the data well.



On the other hand, fitting estimates for the
average height of all humans in each year
with a linear function seems less
"scientific".  Even if the data looks
basically like a noise linear process, we do
not expect at all that if we measured more
and more people (or more and more years in
the past/future) that the linear model would
continue to perform well. For a model to be
a "scientific model", we must <em>reasonably
    expect</em>that the model will continue
to work as we collect more measurements.


Don't get me wrong, statistics is
incredibly important to the scientific
process.
<!-- Fits from statistical models -->
<!-- can even be used as inputs (assumptions) for -->
<!-- more scientific models (if we simply show -->
<!-- that the consequences of the scientific -->
<!-- model we care about don't depend strongly on -->
<!-- the exactly output of the statistical -->
<!-- model). -->
But a the slope of linear model fit to a
cloud of data should not be called a
"scientific" finding. It is (merely) a
statistical finding.
#### Things that are science


Many theoreticians would probably take
offense to my requirement that scientific
models need to be expected to be able to
reproduce experimental data arbitrarily
well. After all, many models (my entire
scientific career included) are considered
worthwhile not because they can reproduce
experimental measurements. For example,
a very popular approach widely known as
"bottom-up" modeling totally eschews
attempting to match any data at all.
Instead, bottom-up modeling takes small
subset of only the most well-accepted facts
about a complex system and tries to derive
the consequences of only that subset of
properties. By doing so, the modeling
process is made infinitely more tractable,
and the individual effects from the
different parts of the system can often be
teased apart much more easily. However, this
of course comes at the cost of being able to
reproduce data.



#### Assumption complexity: a useful classifier for "types" of science


I find that one of the most useful metrics
by which to classify scientific models is
by how detailed the assumptions need to be
in order to produce the model's logical
conclusions (given our current understanding
of mathematics).



On one extreme, you'll tend to find
models that come out of very applied fields
such as biology or materials science. Say
you are interested in the science behind how
a microbe works. It's entirely possible that
in order to develop a model that faithfully
reproduces every facet of such a complicated
entity, you need to basically plug in so
many details (assumptions) about the microbe
in question that you begin to ask yourself
if you're actually learning anything or just
carefully reverse-engineering. These models
gain their utility from being able to
explain specific systems that affect humans
here and now.



On the other extreme, you'll tend to find
models from more "theoretical" fields such
as physics or computer science.
Practitioners of these fields will tend to
specifically be interested in what logical
conclusions can be drawn from small sets of
assumptions. For example, a physicist might
ask what assumptions can be drawn about the
electromagnetic force assuming a particular
type of symmetry (locally U(1)) that it has
been observed to obey. These models will
contain a very small set of assumptions and
as provide utility by being broadly
applicable to a wide range of problems.



Both types (and everything in between) are
useful. Both types are science.


Are there things which are "not"
science? Definitely. </>

<!-- first version -->


Any attempts to build a falsifiable model
that describes observations about the world
around us is science, as is the testing of
such a model, as is the exploration of
potentially unexplored types of measurements
about the world with the purpose of building
a model. At least that's a tempting thing to
say, and maybe it summarizes the most
well-accepted bits of the "philosophy of
science", from Bacon, to Popper to
Hempel.
<!--
However, I often see this definition -->
<!-- being used as a sort of checklist, by people -->
<!-- that want to do "science", but somehow end -->
<!-- up doing bad stats on ugly data. -->


<strong>BUT</strong>, I think that almost
any modern scientist, if forced to, could do
a much better job at describing what is
meant at the turn of the 21st century by
"good" science than this simple description.
<!-- It's easy to do better than centuries of -->
<!-- brilliant philosophers at describing -->
<!-- something that you have centuries more -->
<!-- examples of, but we're going to do it -->
<!-- anyway. -->



First, what is so bad about the previous
definition? When used as a checklist, it
allows one to call a lot of things science
that a working scientist would take great
offense to. For example, say I measure a
bunch of people's heights over the last few
decades. Now I fit a line to their heights
as a function of time. I claim that people's
heights are growing at an average rate given
by the parameter of my model fit. The number
of ways in which this is "hardly" science
are almost too numerous for any working
scientist to point out, but it seems to
check all of the boxes! There's a model
(albeit an unmotivated, oversimplied,
seemingly arbitrary one). It's falsifiable
(more measurements, or maybe measurements in
the future or past could show that this
trend no longer holds or never held at all).
My measurements might have been the first of
their kind, I might have predicted height
would increase on average over time <i>a
priori</i>, and still no scientist worth
their salt would call what I did science.
Maybe if confronted with a definition of
science like the one above, they would cave
and just mutter that it's not "good" science
in any case. Many of the less policitally
correct...physicists...in the room would
even be likely to mutter that "this might
pass for real work in the social sciences,
but not in [my] department."



Now I don't agree with my colleagues that
think that social sciences are "lesser" than
the "hard" sciences, but the things they are
recoiling at stem from a shared
understanding of what types of science are
useful, what types of scientific questions
tend to be fruitful, and what types of
approaches tend to most often lead to bogus
results. The above example really does go
against dozens of unspoken "rules" about
what is allowed to be called science within
the community. They recoil because such a
seemingly useless piece of work flows
directly against the zeitgeist of early
21st century science, and this zeitgeist
exists for a reason.


Well, the obvious follow-up question is:
can we amend our previous definition of
science to more completely contain this
shared understanding of what constitutes
"real" science, as opposed to things that
simply masquerade as scientific? Of course,
as someone whose graduate "schooling" was
largely <a href="#blog.physics-vs-biology">
guided by physicists</a>, it is my solemn
duty to believe that not only can I
summarize this complex set of rules, but
that I can do so in a manner that distills
them into a much simpler set of underlying
principles that should drive how everybody
does science.

Jokes aside, dozens of much smarter
people than me have tried this same exercise
over the centuries since humans have left
behind writings about science. However, like
a middle schooler solving algebraic
equations that only specialized
mathematicians would have been acquainted
with in ancient times, I have the advantage
of modernity: everything is much easier in
hindsight.



In order to better define what science is,
we're going to sketch out a model for how an
abstract (set of) agent(s) might go about
discovering things about the world around
themselves. I don't intend to provide a
rigorous definition or exmaple of such a
model, but merely to point out the types of
strategies that might emerge, so that I can
more precisely specify which of these I
would call "science".



So if you want a model describing a set of
agents trying to discover the universe
around them, you need to specify something
about the universe that you're talking
about. And if you want to say things about
how universally applicable their strategy
is, you need to in fact describe the sets of
universes over which you want to gauge their
potential for success.



This may seem like a silly proposition, but
I'd argue that we can quickly list off
various properties of universes that are
necessary for the question we're asking to
even make sense in the first place.

<ul>
    <li>The universe better be complex
        enough that it can support (as in it
        can contain) agents that can ask
        questions about the universe.</li>
    <li>On the time scales on which these
        agents ask their question, the
        universe better have at least
        reasonably constant underlying
        rules. </li>
</ul>


The complexity lower-bound means that the
universes we're talking about have to at
least admit turing-complete machines.
The other property is mostly just to
simplify the questions that we're asking.
And while there are
<a href="https://en.wikipedia.org/wiki/Time-variation_of_fundamental_constants">
    valid reasons to ask if the laws of
    physics as-currently-written describe
    rules about our own universe that are
    actually "unchanging"</a>,
the majority of the scientific community can
safely assume that the fundamental laws of
physics are unchanging (hence the
"reasonably" above).



For our model of the "scientific" process,
we will consider a observable universe, a
set of existing observations, and a set of
(possibly evolving) methods for generating
new obsevations. A "knowledge set" contains
a set of patterns that have been observed to
hold (exactly, statistically, or otherwise)
in the existing observations.

We define "reason" to be the set of rules by
which the elements of the "knowledge set"
are assigned "confidences". And we define
"science" to be the proess by which new
patterns in existing observations are
searched for (hypothesis development), their
consequences are enumerated (theoretical
development, i.e. mathematics), and new
measurements are chosen with which to
attempt to verify or falsify existing
hypotheses.



Is reason just really fancy statistical
pattern-matching with some kind of power-law
memory decay? Yeah probably.



In this framework, some "good" types of
science are:

<ul>
<li>Finding</li>
<li>Finding consequences of
high-confidence hypotheses that
directly contradict low-consequence
hypotheses, and removing the
contradictory low-confidence
hypothesis.</li>
<li>Finding consequences of
high-confidence hypotheses that are
also in our knowledge set. Patterns
in our knowledge set that are </li>
</ul>




